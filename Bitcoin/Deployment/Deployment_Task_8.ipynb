{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deployment_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTETaezjRJCn"
      },
      "source": [
        "#Productization and Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMaIgLqkQ-ss"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVRY7J6nQkTq",
        "outputId": "2bbb4a7c-f7d7-4c33-e141-60bc9fdf6632",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Bitcoin_2017 = pd.read_csv('/content/drive/My Drive/Technocolabs Internship Project/bitcoin_cash_price.csv')\n",
        "Bitcoin_2017.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Feb 20, 2018</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Feb 19, 2018</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Feb 18, 2018</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feb 17, 2018</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Feb 16, 2018</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date     Open     High  ...    Close       Volume      Market Cap\n",
              "0  Feb 20, 2018  1543.27  1569.03  ...  1418.73  820,947,000  26,199,800,000\n",
              "1  Feb 19, 2018  1483.34  1553.81  ...  1534.77  578,906,000  25,179,700,000\n",
              "2  Feb 18, 2018  1552.10  1641.40  ...  1487.46  907,873,000  26,344,200,000\n",
              "3  Feb 17, 2018  1548.48  1568.64  ...  1551.39  641,719,000  26,280,100,000\n",
              "4  Feb 16, 2018  1373.16  1558.66  ...  1552.20  961,010,000  23,302,000,000\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC0LjrMvVLqI",
        "outputId": "341b6dec-ae6b-4c93-fe1c-e54f0f63c371",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Bitcoin_2017.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 213 entries, 0 to 212\n",
            "Data columns (total 7 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        213 non-null    object \n",
            " 1   Open        213 non-null    float64\n",
            " 2   High        213 non-null    float64\n",
            " 3   Low         213 non-null    float64\n",
            " 4   Close       213 non-null    float64\n",
            " 5   Volume      213 non-null    object \n",
            " 6   Market Cap  213 non-null    object \n",
            "dtypes: float64(4), object(3)\n",
            "memory usage: 11.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jYuZspKUj_C"
      },
      "source": [
        "Bitcoin_2017['Date'] = pd.to_datetime(Bitcoin_2017['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QUgZQmnVvAb",
        "outputId": "056c273d-79e3-434b-9a62-1bbb7e119d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Bitcoin_2017.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date     Open     High      Low    Close       Volume      Market Cap\n",
              "0 2018-02-20  1543.27  1569.03  1414.35  1418.73  820,947,000  26,199,800,000\n",
              "1 2018-02-19  1483.34  1553.81  1483.34  1534.77  578,906,000  25,179,700,000\n",
              "2 2018-02-18  1552.10  1641.40  1428.49  1487.46  907,873,000  26,344,200,000\n",
              "3 2018-02-17  1548.48  1568.64  1517.14  1551.39  641,719,000  26,280,100,000\n",
              "4 2018-02-16  1373.16  1558.66  1369.68  1552.20  961,010,000  23,302,000,000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_x3itFZENAA"
      },
      "source": [
        "# creating a column `iso_week` by stripping the Year and Week from `date`\n",
        "Bitcoin_2017['iso_week'] = Bitcoin_2017['Date'].apply(\n",
        "    lambda x: x.strftime('%Y-%U'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9ixU1VEhH3z"
      },
      "source": [
        "Bitcoin_2017['week'] = Bitcoin_2017['Date'].apply(\n",
        "    lambda x: x.strftime('%U'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb3jY4mgEdX1",
        "outputId": "b368a4e4-142d-47d0-9765-b9e8d8e73786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Bitcoin_2017.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820,947,000</td>\n",
              "      <td>26,199,800,000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578,906,000</td>\n",
              "      <td>25,179,700,000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907,873,000</td>\n",
              "      <td>26,344,200,000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641,719,000</td>\n",
              "      <td>26,280,100,000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961,010,000</td>\n",
              "      <td>23,302,000,000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Date     Open     High  ...      Market Cap  iso_week week\n",
              "0 2018-02-20  1543.27  1569.03  ...  26,199,800,000   2018-07   07\n",
              "1 2018-02-19  1483.34  1553.81  ...  25,179,700,000   2018-07   07\n",
              "2 2018-02-18  1552.10  1641.40  ...  26,344,200,000   2018-07   07\n",
              "3 2018-02-17  1548.48  1568.64  ...  26,280,100,000   2018-06   06\n",
              "4 2018-02-16  1373.16  1558.66  ...  23,302,000,000   2018-06   06\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isYBdLAYhQKA"
      },
      "source": [
        "# changing the dtypes\n",
        "Bitcoin_2017['week']=Bitcoin_2017['week'].astype(int)\n",
        "Bitcoin_2017['Date']=Bitcoin_2017['Date'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtlYHlqwwl0a"
      },
      "source": [
        "# Removing the ',' from Volume and Market Cap\n",
        "Bitcoin_2017['Volume'] = Bitcoin_2017['Volume'].apply(lambda x: x.replace(',', ''))\n",
        "Bitcoin_2017['Market Cap'] = Bitcoin_2017['Market Cap'].apply(lambda x: x.replace(',', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4BRpFMzyYF8"
      },
      "source": [
        "Bitcoin_2017['Volume'] = Bitcoin_2017['Volume'].astype(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYV81f4CxZhM",
        "outputId": "3a03f069-9ddc-45f6-a4fc-5710f32239da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Bitcoin_2017.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000</td>\n",
              "      <td>26199800000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000</td>\n",
              "      <td>25179700000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000</td>\n",
              "      <td>26344200000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000</td>\n",
              "      <td>26280100000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000</td>\n",
              "      <td>23302000000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Open     High      Low  ...     Volume   Market Cap iso_week week\n",
              "0  2018-02-20  1543.27  1569.03  1414.35  ...  820947000  26199800000  2018-07    7\n",
              "1  2018-02-19  1483.34  1553.81  1483.34  ...  578906000  25179700000  2018-07    7\n",
              "2  2018-02-18  1552.10  1641.40  1428.49  ...  907873000  26344200000  2018-07    7\n",
              "3  2018-02-17  1548.48  1568.64  1517.14  ...  641719000  26280100000  2018-06    6\n",
              "4  2018-02-16  1373.16  1558.66  1369.68  ...  961010000  23302000000  2018-06    6\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtV_2hpHxf0P",
        "outputId": "eb6260d4-da80-4900-d45f-09a1fb489cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Bitcoin_2017.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 213 entries, 0 to 212\n",
            "Data columns (total 9 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Date        213 non-null    object \n",
            " 1   Open        213 non-null    float64\n",
            " 2   High        213 non-null    float64\n",
            " 3   Low         213 non-null    float64\n",
            " 4   Close       213 non-null    float64\n",
            " 5   Volume      213 non-null    int64  \n",
            " 6   Market Cap  213 non-null    object \n",
            " 7   iso_week    213 non-null    object \n",
            " 8   week        213 non-null    int64  \n",
            "dtypes: float64(4), int64(2), object(3)\n",
            "memory usage: 15.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGS8ZaXzz7xQ"
      },
      "source": [
        "Def Functions using in this session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiGUJpo0zOtG"
      },
      "source": [
        "\"\"\"\n",
        "Series of normalization functions useful\n",
        "for normalizing time-series data.\n",
        "\"\"\"\n",
        "\n",
        "def z_score(series):\n",
        "    \"\"\"\n",
        "    Computes the normalized value using the Z-score\n",
        "    technique. The Z-score is a technique used for\n",
        "    normalizing Gaussian distributions representing\n",
        "    each observation in relation to the distribution's\n",
        "    mean and standard deviation. For precise definitions,\n",
        "    see the Wikipedia article:\n",
        "    \n",
        "        https://en.wikipedia.org/wiki/Standard_score\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    result = (series - series.mean()) / series.std(ddof=0)\n",
        "    return result\n",
        "\n",
        "def point_relative_normalization(series, reverse=False, last_value=None):\n",
        "    \"\"\"\n",
        "    Computes the normalized value for the values of a\n",
        "    given series by using the first element of the serie as p_0\n",
        "    as a reference for each p_i.\n",
        "    \n",
        "    This technique comes from Siraj Raval's YouTube video\n",
        "    \"How to Predict Stock Prices Easily - Intro to Deep Learning #7\",\n",
        "    available at:\n",
        "    \n",
        "        https://www.youtube.com/watch?v=ftMq5ps503w\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    reverse: bool, default True\n",
        "        If the method should de-normalize data.\n",
        "    \n",
        "    last_value: int or float\n",
        "        Used to de-normalize a dataset. Needs to \n",
        "        be passed if `reverse` is True.\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    if reverse:\n",
        "        result = last_value * (series + 1)\n",
        "    else:\n",
        "        result = (series / series[0]) - 1\n",
        "\n",
        "    return result\n",
        "\n",
        "def maximum_and_minimum_normalization(series, boundary=(0, 1)):\n",
        "    \"\"\"\n",
        "    Computes the normalized value for the values of a\n",
        "    given serie by using that series maximum and minimum\n",
        "    values.\n",
        "    \n",
        "    This technique is a direct implementation from \n",
        "    scikit-learn, available at:\n",
        "    \n",
        "        http://scikit-learn.org/stable/modules/generated/\\\n",
        "            sklearn.preprocessing.MinMaxScaler.html\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    serie: list\n",
        "        List with sequential values to use.\n",
        "    \n",
        "    boundary: set\n",
        "        Maximum and minimum values used to\n",
        "        scale the series.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    result: list\n",
        "        List with the normalized results.\n",
        "    \"\"\"\n",
        "    range_min, range_max = boundary\n",
        "    standard_deviation = (series - series.min(axis=0)) / (series.max(axis=0) - series.min(axis=0))\n",
        "    result = standard_deviation * (range_max - range_min) + range_min\n",
        "    return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OcSUxswz_Mi"
      },
      "source": [
        "\"\"\"\n",
        "Helper class and methods for making manipulating\n",
        "data for models.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "\n",
        "#from cryptonic.models import normalizations\n",
        "\n",
        "\n",
        "class ModelHelper:\n",
        "    \"\"\"\n",
        "    Class with utility functions that aid in \n",
        "    the process of training LSTM models with Keras.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def create_groups(self, data, start=0, group_size=7, normalize=True):\n",
        "        \"\"\"\n",
        "        Creates distinct groups from a given continuous series.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        data: np.array\n",
        "            Series of continious observations.\n",
        "        \n",
        "        start: int\n",
        "            Starting point for the series. This \n",
        "            is used to prune earlier observations\n",
        "            from the series in case the series is\n",
        "            too long or too short.\n",
        "\n",
        "        group_size: int, default 7\n",
        "            Determines how large the groups are. That is,\n",
        "            how many observations each group contains.\n",
        "        \n",
        "        normalize: bool\n",
        "            If the method should normalize data or not.\n",
        "            Normalization is done using \n",
        "\n",
        "                point_relative_normalization()\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        A Numpy array object. \n",
        "        \"\"\"\n",
        "        samples = list()\n",
        "        for i in range(0, len(data), group_size):\n",
        "            sample = list(data[start + i:i + group_size])\n",
        "            if len(sample) == group_size:\n",
        "                if normalize:\n",
        "                    sample = point_relative_normalization(sample)\n",
        "\n",
        "                samples.append(np.array(sample).reshape(1, group_size).tolist())\n",
        "\n",
        "        A = np.array(samples)\n",
        "        return A.reshape(1, A.shape[0], group_size)\n",
        "\n",
        "    def split_lstm_input(self, groups):\n",
        "        \"\"\"\n",
        "        Splits groups in a format expected by \n",
        "        the LSTM layer. \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        groups: np.array\n",
        "            Numpy array with the organized sequences.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        X, Y: np.array\n",
        "            Numpy arrays with the shapes required by\n",
        "            the LSTM layer. X with (1, a - 1, b)\n",
        "            and Y with (1, b). Where a is the total\n",
        "            number of groups in `group` and b the\n",
        "            number of observations per group.\n",
        "        \"\"\"\n",
        "        X = groups[0:,:-1].reshape(1, groups.shape[1] - 1, groups.shape[2])\n",
        "        Y = groups[0:,-1:][0]\n",
        "\n",
        "        return X, Y\n",
        "\n",
        "    def normalize(self):\n",
        "        \"\"\"\n",
        "        Normalizes a series using point-relative normalization.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        point_relative_normalization()\n",
        "\n",
        "    def denormalize(self, series, last_value):\n",
        "        \"\"\"\n",
        "        De-normalizes a series using the latest\n",
        "        value available from data.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        series: numpy array\n",
        "            Series with normalized values.\n",
        "        \n",
        "        last_value: float\n",
        "            Numerical value that represents the\n",
        "            last value from the dataset.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        \"\"\"\n",
        "        result = last_value * (series + 1)\n",
        "        return result\n",
        "\n",
        "    def mape(self, A, B):\n",
        "        \"\"\"\n",
        "        Calcualtes the mean absolute persentage error\n",
        "        from two series. Original solution from:\n",
        "        \n",
        "            https://stats.stackexchange.com/questions/58391/\\\n",
        "                mean-absolute-percentage-error-mape-in-scikit-learn\n",
        "        \"\"\"\n",
        "        return np.mean(np.abs((A - B) / (1 - A))) * 100\n",
        "\n",
        "    def rmse(self, A, B):\n",
        "        \"\"\"\n",
        "        Calculates the root mean square error from\n",
        "        two series. Original solution from:\n",
        "\n",
        "            https://stackoverflow.com/questions/16774849\\\n",
        "                /mean-squared-error-in-numpy\n",
        "        \"\"\"\n",
        "        return np.sqrt(np.square(np.subtract(A, B)).mean())\n",
        "    \n",
        "    def mse(self, A, B):\n",
        "        \"\"\"\n",
        "        Calculates the mean square error from\n",
        "        two series. Original solution from:\n",
        "\n",
        "            https://stackoverflow.com/questions/16774849\\\n",
        "                /mean-squared-error-in-numpy\n",
        "        \"\"\"\n",
        "        return np.square(np.subtract(A, B)).mean()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk6olrw20AmE"
      },
      "source": [
        "\"\"\"\n",
        "Creates a deep learning model abstraction.\n",
        "\"\"\"\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers.core import Dense, Activation\n",
        "\n",
        "#from cryptonic.models.helper import ModelHelper\n",
        "#from cryptonic.models.normalizations import point_relative_normalization\n",
        "\n",
        "\n",
        "class Model(ModelHelper):\n",
        "    \"\"\"\n",
        "    Class that encapsulates an LSTM model\n",
        "    that we have been building. This class makes it\n",
        "    easy to work with the different functions\n",
        "    used to work with the model.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    path: str\n",
        "        Location to load model from.\n",
        "\n",
        "    data: pandas DataFrame\n",
        "        Pandas dataframe with the variable from\n",
        "        `variable` privided. This is used\n",
        "        to eventually train and run the model.\n",
        "    \n",
        "    variable: str\n",
        "        Variable to use from `data`.\n",
        "    \n",
        "    predicted_period_size: int\n",
        "        Number of predicted time periods predictions\n",
        "        to make.\n",
        "    \n",
        "    holdout: int, default 0\n",
        "        Number of periods to hold-out from the \n",
        "        training set.\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, data, variable, predicted_period_size, path=None, \n",
        "                 holdout=0, normalize=True):\n",
        "\n",
        "        self.path = path\n",
        "        self.data = data\n",
        "        self.variable = variable\n",
        "        self.predicted_period_size = predicted_period_size\n",
        "        self.holdout = holdout\n",
        "\n",
        "        if path:\n",
        "            self.model = load_model(self.path)\n",
        "\n",
        "        self.X, self.Y = self.__prepare_data(normalize=normalize)\n",
        "        self.__extract_last_series_value()\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "    def __extract_last_series_value(self):\n",
        "        \"\"\"\n",
        "        Method for extracting the last value from\n",
        "        a series prior to normalization. This value\n",
        "        is then used for denormalizing the set.\n",
        "        \"\"\"\n",
        "        if self.remainder:\n",
        "            self.last_value = self.data.sort_values('date', ascending=False)\\\n",
        "                                [:-self.remainder][self.variable].values[0]\n",
        "            \n",
        "            self.last_date = self.data.sort_values('date', ascending=False)\\\n",
        "                                [:-self.remainder]['date'].values[0]\n",
        "        else:\n",
        "            self.last_value = self.data.sort_values('date', ascending=False)\\\n",
        "                                [self.variable].values[0]\n",
        "            \n",
        "            self.last_date = self.data.sort_values('date', ascending=False)\\\n",
        "                                ['date'].values[0]\n",
        "    \n",
        "    def __prepare_data(self, normalize):\n",
        "        \"\"\"\n",
        "        Prepares data for model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        normalize: bool\n",
        "            If the method should normalize data or not.\n",
        "            Normalization is done using \n",
        "\n",
        "                point_relative_normalization()\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X and Y prepared for training.\n",
        "        \"\"\"\n",
        "        series = self.data[self.variable].values\n",
        "        self.remainder = len(series) % self.predicted_period_size\n",
        "\n",
        "        groups = self.create_groups(data=series, \n",
        "                                    group_size=self.predicted_period_size,\n",
        "                                    normalize=normalize)\n",
        "        \n",
        "        if self.holdout == 0:\n",
        "            self.holdout_groups = []\n",
        "        else:\n",
        "            self.holdout_groups = groups[::-self.holdout]\n",
        "            groups = groups[::-self.holdout]\n",
        "\n",
        "        self.default_number_of_periods = groups.shape[1] - 1\n",
        "\n",
        "        return self.split_lstm_input(groups)\n",
        "\n",
        "    def build(self, number_of_periods=None, period_length=7, batch_size=1):\n",
        "        \"\"\"\n",
        "        Builds an LSTM model using Keras. This function\n",
        "        works as a simple wrapper for a manually created\n",
        "        model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        period_length: int\n",
        "            The size of each observation used as input.\n",
        "        \n",
        "        number_of_periods: int, default None\n",
        "            The number of periods available in the \n",
        "            dataset. If None, the model will be built\n",
        "            using all available periods - 1 (used for validation).\n",
        "        \n",
        "        batch_size: int\n",
        "            The size of the batch used in each training\n",
        "            period.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        model: Keras model\n",
        "            Compiled Keras model that can be trained\n",
        "            and stored in disk.\n",
        "        \"\"\"\n",
        "        if not number_of_periods:\n",
        "            number_of_periods = self.default_number_of_periods\n",
        "\n",
        "        self.model = Sequential()\n",
        "        self.model.add(LSTM(\n",
        "            units=period_length,\n",
        "            batch_input_shape=(batch_size, number_of_periods, period_length),\n",
        "            input_shape=(number_of_periods, period_length),\n",
        "            return_sequences=False, stateful=False))\n",
        "\n",
        "        self.model.add(Dense(units=period_length))\n",
        "        self.model.add(Activation(\"linear\"))\n",
        "\n",
        "        self.model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def save(self, path):\n",
        "        \"\"\"\n",
        "        Stores trained model in disk. Useful\n",
        "        for storing trained models.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        path: str\n",
        "            Location of where to store model.\n",
        "        \"\"\"\n",
        "        return self.model.save(path)\n",
        "    \n",
        "    def predict(self, denormalized=False, return_dict=False):\n",
        "        \"\"\"\n",
        "        Makes a prediction based on input data.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        denormalized: bool, default True\n",
        "            If method should denormalize data. Method\n",
        "            will use the point_relative_normalization()\n",
        "        \n",
        "        return_dict: bool, default False\n",
        "            If should return dict that can be serializable\n",
        "            as JSON. Useful for returning prediction\n",
        "            results with dates as keys.\n",
        "\n",
        "        \"\"\"\n",
        "        predictions = self.model.predict(x=self.X)\n",
        "        if denormalized:\n",
        "            predictions = point_relative_normalization(series=predictions, \n",
        "                                                       reverse=True, \n",
        "                                                       last_value=self.last_value)\n",
        "        \n",
        "        dates = []\n",
        "        base_date = datetime.strptime(self.last_date, \"%Y-%m-%d\")\n",
        "        for i in range(1, len(predictions[0] + 1)):\n",
        "            d = (base_date + timedelta(days=i)).strftime(\"%Y-%m-%d\")\n",
        "            dates.append(d)\n",
        "\n",
        "        results = []\n",
        "        for d,p in zip(dates, predictions[0].tolist()):\n",
        "            results.append({\n",
        "                'date': d,\n",
        "                'prediction': round(p, 2)\n",
        "            })\n",
        "        \n",
        "        if return_dict:\n",
        "            return results\n",
        "        \n",
        "        else:\n",
        "            return predictions[0]\n",
        "\n",
        "    def train(self, data=None, epochs=300, verbose=0):\n",
        "        \"\"\"\n",
        "        Trains model using data from class. \n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X: pandas DataFrame\n",
        "            Pandas dataframe with `variable` used to\n",
        "            fir model for the fist time.\n",
        "\n",
        "        epochs: int\n",
        "            Number of epochs to train model for.\n",
        "        \n",
        "        verbose: int, default 0\n",
        "            Verbosity level to use. The default (0)\n",
        "            means that nothing is printed on the\n",
        "            screen.\n",
        "        \n",
        "        Returns\n",
        "        -------\n",
        "        Metrics from the model history.\n",
        "        \"\"\"\n",
        "        if data is not None:\n",
        "            self.data = data\n",
        "            self.X, self.Y = self.__prepare_data(normalize=self.normalize)\n",
        "            self.__extract_last_series_value()\n",
        "\n",
        "        self.train_history = self.model.fit(\n",
        "            x=self.X, y=self.Y,\n",
        "            batch_size=1, epochs=epochs,\n",
        "            verbose=verbose, shuffle=False)\n",
        "        #now = datetime.now()\n",
        "        #self.last_trained = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        return self.train_history\n",
        "\n",
        "    def evaluate(self, metrics=['mse', 'rmse', 'mape']):\n",
        "        \"\"\"\n",
        "        Evaluates model using provided metrics. The evaluation\n",
        "        \"\"\"\n",
        "        y = point_relative_normalization(series=self.Y[0], \n",
        "                                         reverse=True, \n",
        "                                         last_value=self.last_value)\n",
        "\n",
        "        results = {}\n",
        "        for metric in metrics:\n",
        "            if metric == 'mse':\n",
        "                r = round(\n",
        "                        self.mse(A=self.Y[0], B=self.predict()), 2)\n",
        "\n",
        "            else:\n",
        "                r = round(\n",
        "                        getattr(self, metric)(\n",
        "                        A=self.predict(denormalized=True)[0], \n",
        "                        B=y), 2)\n",
        "\n",
        "            results[metric] = r\n",
        "\n",
        "        return results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdwALcxE0B5f"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import time\n",
        "import pytz\n",
        "import json\n",
        "\n",
        "import math  \n",
        "\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "from threading import Thread\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "\n",
        "\n",
        "from sklearn import preprocessing, model_selection, neighbors, svm\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "from tqdm import tqdm as tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTxonjL70Has",
        "outputId": "ebc01449-9c56-4d93-90cc-54a21a0cd47d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "Bitcoin_2017.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Market Cap</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>week</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>1543.27</td>\n",
              "      <td>1569.03</td>\n",
              "      <td>1414.35</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000</td>\n",
              "      <td>26199800000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1553.81</td>\n",
              "      <td>1483.34</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000</td>\n",
              "      <td>25179700000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>1552.10</td>\n",
              "      <td>1641.40</td>\n",
              "      <td>1428.49</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000</td>\n",
              "      <td>26344200000</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>1548.48</td>\n",
              "      <td>1568.64</td>\n",
              "      <td>1517.14</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000</td>\n",
              "      <td>26280100000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>1373.16</td>\n",
              "      <td>1558.66</td>\n",
              "      <td>1369.68</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000</td>\n",
              "      <td>23302000000</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date     Open     High      Low  ...     Volume   Market Cap iso_week week\n",
              "0  2018-02-20  1543.27  1569.03  1414.35  ...  820947000  26199800000  2018-07    7\n",
              "1  2018-02-19  1483.34  1553.81  1483.34  ...  578906000  25179700000  2018-07    7\n",
              "2  2018-02-18  1552.10  1641.40  1428.49  ...  907873000  26344200000  2018-07    7\n",
              "3  2018-02-17  1548.48  1568.64  1517.14  ...  641719000  26280100000  2018-06    6\n",
              "4  2018-02-16  1373.16  1558.66  1369.68  ...  961010000  23302000000  2018-06    6\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4nJUK-S0bXA",
        "outputId": "c9dd6327-fc18-4241-c908-e46d442f5faa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Bitcoin_2017.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date          0\n",
              "Open          0\n",
              "High          0\n",
              "Low           0\n",
              "Close         0\n",
              "Volume        0\n",
              "Market Cap    0\n",
              "iso_week      0\n",
              "week          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozDlg0KB0exk",
        "outputId": "66b82c5b-97bf-4994-bda6-600c4577ae9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#  Time-series plot for `close` variable\n",
        "Bitcoin_2017.set_index('Date')['Close'].plot(\n",
        "    linewidth=2,\n",
        "    figsize=(14, 4),\n",
        "    color='#d35400');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-24id_SZ1kVi",
        "outputId": "3bb0c119-75e4-4f93-dd2c-15314759ca3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        }
      },
      "source": [
        "#  Time-series plot for `Volume` variable\n",
        "Bitcoin_2017.set_index('Date')['Volume'].plot(\n",
        "    linewidth=2,\n",
        "    figsize=(14, 4),\n",
        "    color='#d35400');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZzSPam20lJR"
      },
      "source": [
        "#\n",
        "#  Using the Pandas API, filter the dataframe\n",
        "#  for observations from 2017 only. \n",
        "# \n",
        "#  Hint: use the `date` variable.\n",
        "#\n",
        "\n",
        "Bitcoin_2017 = Bitcoin_2017[Bitcoin_2017['Date'] >= '2017-01-01']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFNrGyMK1rTj",
        "outputId": "4241fd73-ea37-4817-f46e-cd42cf3b9b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "#  Keep only the `close` and `volume` variables\n",
        "model_data = Bitcoin_2017[['Date', 'iso_week', 'Close', 'Volume']]\n",
        "model_data.columns = ['date', 'iso_week', 'close', 'volume']\n",
        "model_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date iso_week    close     volume\n",
              "0  2018-02-20  2018-07  1418.73  820947000\n",
              "1  2018-02-19  2018-07  1534.77  578906000\n",
              "2  2018-02-18  2018-07  1487.46  907873000\n",
              "3  2018-02-17  2018-06  1551.39  641719000\n",
              "4  2018-02-16  2018-06  1552.20  961010000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7h56zQ34V3d"
      },
      "source": [
        "#mean_close = model_data.close.dropna().mean()\n",
        "#max_close = model_data.close.dropna().max()\n",
        "#min_close = model_data.close.dropna().min()\n",
        "#model_data['close_point_relative_normalization'] = model_data.groupby('iso_week')['close'].apply(lambda x: (x - mean_close ) / (max_close -min_close ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBzvL6JU5WmF"
      },
      "source": [
        "#mean_volume = model_data.volume.dropna().mean()\n",
        "#max_volume = model_data.volume.dropna().max()\n",
        "#min_volume = model_data.volume.dropna().min()\n",
        "#model_data['volume_point_relative_normalization'] = model_data.groupby('iso_week')['volume'].apply(lambda x: (x - mean_volume ) / (max_volume -min_volume ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atLRFP6i5hwD",
        "outputId": "b8c14784-f670-48c9-822a-6fcf7e88a293",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "model_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>iso_week</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-02-20</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1418.73</td>\n",
              "      <td>820947000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-02-19</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1534.77</td>\n",
              "      <td>578906000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-02-18</td>\n",
              "      <td>2018-07</td>\n",
              "      <td>1487.46</td>\n",
              "      <td>907873000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-02-17</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>1551.39</td>\n",
              "      <td>641719000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-02-16</td>\n",
              "      <td>2018-06</td>\n",
              "      <td>1552.20</td>\n",
              "      <td>961010000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         date iso_week    close     volume\n",
              "0  2018-02-20  2018-07  1418.73  820947000\n",
              "1  2018-02-19  2018-07  1534.77  578906000\n",
              "2  2018-02-18  2018-07  1487.46  907873000\n",
              "3  2018-02-17  2018-06  1551.39  641719000\n",
              "4  2018-02-16  2018-06  1552.20  961010000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcG3PVKl-EYY"
      },
      "source": [
        "## The `Model()` Class\n",
        "We have also created the class `Model()` which compiles all the code we have written so far. We will use that class to build, train, and evaluate our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKxm3TLt5kC8"
      },
      "source": [
        "M = Model(data=model_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvarV9GJ-GNM",
        "outputId": "4537dd7a-2839-4637-cd42-74f9dab5e309",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.build()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.engine.sequential.Sequential at 0x7fe542bed748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3RsPXp8-sG2",
        "outputId": "f5f8a895-bc3a-4b90-8cef-b6ad1164e4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.train(epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0138\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0125\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 0.0117\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 942us/step - loss: 0.0110\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0104\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0098\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0094\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 945us/step - loss: 0.0089\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 941us/step - loss: 0.0085\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0081\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0077\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0074\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0067\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0063\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0060\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0057\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0054\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0051\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0047\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0044\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0041\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0039\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 999us/step - loss: 0.0036\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0033\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0030\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 968us/step - loss: 0.0028\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 925us/step - loss: 0.0025\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0023\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0020\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 991us/step - loss: 0.0018\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0016\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0014\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0012\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0011\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1605e-04\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.7975e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5765e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4913e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5391e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7105e-04\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0004e-04\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3974e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8938e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4775e-04\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1398e-04\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6847e-05\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5572e-05\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8964e-05\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6442e-05\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6891e-05\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 977us/step - loss: 2.0003e-05\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4788e-05\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1228e-05\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4985e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7969e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4451e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7653e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1653e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0529e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8522e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0575e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0415e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4062e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4284e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8421e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8171e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2229e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1356e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5333e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4141e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8325e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7133e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1770e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0659e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5791e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4594e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0073e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8540e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4205e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 974us/step - loss: 7.2216e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8046e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5661e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1786e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9107e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5627e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 913us/step - loss: 8.2591e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.9354e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.5671e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2256e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7659e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3687e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8323e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3830e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8282e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.3697e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.8565e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4292e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9774e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5864e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe54a48a710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsGQY27U-w2B"
      },
      "source": [
        "We can now use the model for making predictions with the `predict()` method. The parameter `denormalized` will return values in the original scale of the data. In our case, US dollars."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQw7uJ3V-tP4",
        "outputId": "4def54dd-471f-4ea5-f7f8-ba94615d9d56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.predict(denormalized=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 26 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe54a169378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00285151, -0.23024562, -0.08907648,  0.01679505,  0.07045399,\n",
              "        0.01351396, -0.03501853], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Bf9don-FxP6"
      },
      "source": [
        "We now evaluate our model to inspect the statistics for the last epoch of training compared to a single test week."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFaA6g97-yTI",
        "outputId": "83d16786-04cf-4065-84eb-ac41e8494365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mape': 6.47, 'mse': 0.0, 'rmse': 135.55}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lQqTqwfF2UB"
      },
      "source": [
        "Finally, we can now save the trained model on disk for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJtuWcN_F1S1"
      },
      "source": [
        "M.save('/content/drive/My Drive/Technocolabs Internship Project/Deployment/bitcoin_model_prod_v0.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvLyLqLyGsH9"
      },
      "source": [
        "Our `Model()` class can also load a previously trained model when instantiated with the `path` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp7Ml_I1Grfz"
      },
      "source": [
        "M = Model(path='/content/drive/My Drive/Technocolabs Internship Project/Deployment/bitcoin_model_prod_v0.h5',\n",
        "          data=model_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JDPmruZFyxD",
        "outputId": "7b3df0bc-d6d6-41a8-eec9-299072919f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M.predict(denormalized=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe54a0c5598> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00285151, -0.23024562, -0.08907648,  0.01679505,  0.07045399,\n",
              "        0.01351396, -0.03501853], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0bWVFmzG_UU"
      },
      "source": [
        "## New Data, Re-train Old Model\n",
        "One strategy discussed earlier regards the re-training of our model with new data. In our case, our biggest concern is to shape data in a way that the model has been configured. As an example, we will configure our model to predict a week using 40 weeks. We will first train the model with the first 40 weeks of 2017, then continue to re-train it over the following weeks until we reach week 50."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIPk4uubHJRf"
      },
      "source": [
        "First, let's build a model with the first set of data. Notice how we use `7*40 + 7` as the indexer. This is because we use 40 weeks for training and 1 week for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCsRq-CHiYA9",
        "outputId": "c773e05f-3552-4678-abf0-3bbbc1256ec5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i=1\n",
        "M1 = Model(data=model_data[i * 7:7 * (40 + i) + 7],variable='close',predicted_period_size=7)\n",
        "M1.build()\n",
        "M1.train()\n",
        "results = [] \n",
        "for i in range(1, 10 + 1):\n",
        "    M1.train(epochs=100, verbose=1)\n",
        "    results.append(M1.evaluate())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7536e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3965e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 971us/step - loss: 7.3135e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 930us/step - loss: 8.6110e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0363e-05\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0642e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 957us/step - loss: 7.8470e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 918us/step - loss: 5.7673e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3127e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8731e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 937us/step - loss: 5.5798e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 888us/step - loss: 5.9338e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8734e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 960us/step - loss: 6.5249e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 996us/step - loss: 6.5361e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0227e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6505e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 854us/step - loss: 6.9622e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2597e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7084e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 877us/step - loss: 6.6153e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8765e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.7273e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.7204e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.9157e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4127e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2288e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9398e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0608e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1345e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1425e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3652e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8396e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0446e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 989us/step - loss: 5.9678e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9541e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8825e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1402e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1626e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5092e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 963us/step - loss: 6.8071e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 925us/step - loss: 7.7946e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9668e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6461e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6443e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1686e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3779e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6619e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1691e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4865e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5049e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3726e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4095e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5289e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6346e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0656e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1242e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2366e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0310e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.4353e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2222e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6721e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0551e-05\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.0538e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6007e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4510e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9778e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 989us/step - loss: 4.6015e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3243e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7025e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.5804e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1518e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.9461e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1309e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4050e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1209e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2880e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3273e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9841e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4476e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.5487e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1967e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 984us/step - loss: 1.0743e-05\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6342e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0428e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.0908e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7693e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5472e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3508e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7265e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4952e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9377e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6285e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8311e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1056e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9412e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3068e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4919e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0938e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4450e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5083e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 9.2785e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0930e-05\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.7187e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0176e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0028e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6457e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4133e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1889e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5702e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3443e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8302e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5142e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6394e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7015e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3812e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.9655e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6770e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4540e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5063e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0379e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 905us/step - loss: 8.7281e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1069e-05\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.4832e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.6973e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2658e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6444e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2093e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8309e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2073e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 986us/step - loss: 6.0870e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8081e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6344e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6679e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3986e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5281e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8999e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3784e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0125e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 987us/step - loss: 7.0115e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5856e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3495e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0200e-05\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0702e-05\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.5125e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 895us/step - loss: 6.2775e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0547e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1017e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.3732e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6058e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5347e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6499e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8712e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 964us/step - loss: 5.0034e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5375e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9906e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4356e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7002e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.5969e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.0207e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2619e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3162e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5132e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9529e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1871e-05\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9469e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8267e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6645e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2350e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9768e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6315e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9817e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7233e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.3952e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1829e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2970e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9559e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8680e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8925e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7003e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3192e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7233e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.5723e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2370e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6813e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1444e-05\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1930e-05\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9129e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8814e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1797e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9895e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8964e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5774e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8626e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4398e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0391e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7931e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0273e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7588e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7454e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7387e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 957us/step - loss: 6.5579e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3492e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 992us/step - loss: 7.8261e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3513e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5675e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.5235e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1345e-05\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3541e-05\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3786e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7963e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4752e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9691e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6115e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0512e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2568e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8601e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7448e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7692e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1685e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8875e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5657e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8810e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8320e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6895e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3216e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7282e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5439e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2231e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5429e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2309e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4009e-05\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.5672e-05\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.6861e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7280e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2823e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6605e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.1745e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3867e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4856e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9870e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1024e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3953e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1658e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1189e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8940e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0959e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.6194e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6517e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 7.2402e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1347e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8697e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5443e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0194e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3653e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9377e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5559e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1142e-05\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4491e-05\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5138e-05\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2457e-05\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0751e-05\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4539e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3888e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7129e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0638e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6502e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6066e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6936e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1019e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7495e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9942e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 924us/step - loss: 5.6080e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8171e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0714e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0101e-05\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.8555e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0880e-05\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0048e-05\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4960e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2828e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7547e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6652e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4891e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6060e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4995e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6756e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5924e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1027e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3115e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1444e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1817e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7477e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2083e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2281e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3718e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1144e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4229e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4035e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5628e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6918e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4435e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5030e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0209e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.9602e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3080e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3694e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2831e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3871e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5968e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5438e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6075e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2100e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8959e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2102e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 956us/step - loss: 7.2560e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.4749e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.6902e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7374e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.9271e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2635e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8060e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4180e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2712e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1595e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.9282e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.4494e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0818e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3569e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.4650e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1353e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1045e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3353e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6229e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4979e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.2407e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6503e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4913e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6053e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8565e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7566e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0334e-05\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6391e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.2797e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5213e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2884e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2863e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9989e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8437e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0331e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2739e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7473e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.1746e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8857e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8162e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3462e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1372e-05\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.2359e-05\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0249e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7157e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 934us/step - loss: 3.8042e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5179e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6119e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7562e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7288e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 895us/step - loss: 6.7439e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3044e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0063e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 938us/step - loss: 5.3903e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2081e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 908us/step - loss: 5.3531e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6971e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8065e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6545e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4330e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0130e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 962us/step - loss: 4.8340e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6706e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 983us/step - loss: 5.3896e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6533e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0963e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 954us/step - loss: 9.1162e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 931us/step - loss: 8.2867e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4514e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 897us/step - loss: 4.1286e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1905e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5431e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5751e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6717e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7467e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1569e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2736e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6627e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4378e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7077e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6855e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 766us/step - loss: 6.3808e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 979us/step - loss: 8.1345e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0546e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6543e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0611e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0818e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7320e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8347e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3230e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8108e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5534e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4706e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3423e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.5559e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.3942e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3532e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6105e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0153e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5715e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0800e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3437e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.8899e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5896e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8711e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6202e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.4104e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7115e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2925e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6314e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1198e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5756e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6208e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2681e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2061e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1723e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3673e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1840e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3387e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6711e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0529e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2283e-05\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1329e-05\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2151e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7043e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7067e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5679e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1902e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5750e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4677e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2808e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0588e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5408e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7071e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3261e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7271e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1522e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0679e-05\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2903e-05\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.5228e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.5073e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6237e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8964e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6252e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5642e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1403e-05\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.2165e-05\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.1348e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9862e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.3245e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4704e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5367e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1319e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 893us/step - loss: 4.4602e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7437e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6762e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4386e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9977e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9859e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4677e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8216e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7156e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5328e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7718e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8400e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2560e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5205e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3328e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9523e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4389e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2275e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0292e-05\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1901e-05\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2268e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5088e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9541e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0509e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4966e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4189e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3702e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2514e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2335e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7241e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0565e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9502e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8972e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4740e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4411e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8974e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.9311e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1029e-05\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4094e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7219e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9886e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3991e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3863e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2910e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9306e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3763e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.7062e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.1467e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8296e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7055e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7900e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.7764e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2657e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7916e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.9433e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.2379e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.0142e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8680e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8084e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3193e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6917e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9897e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8551e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0839e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7810e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8759e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5809e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8089e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7481e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.1519e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1513e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0867e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9399e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2795e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9732e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.2469e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.1781e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.1754e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1683e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0595e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1819e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5785e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.9318e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9773e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6640e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6621e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2143e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.7043e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2121e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0689e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8810e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4366e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3565e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5656e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0222e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.3569e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9841e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5729e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1226e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6526e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 966us/step - loss: 6.0239e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0999e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.0690e-05\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0564e-05\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1771e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0434e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 925us/step - loss: 3.2927e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4665e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9585e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7986e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8008e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0441e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4654e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2054e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 902us/step - loss: 4.1067e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 977us/step - loss: 5.3382e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 995us/step - loss: 6.4726e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.6370e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0725e-05\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 992us/step - loss: 1.1298e-05\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 947us/step - loss: 7.2786e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3169e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 902us/step - loss: 3.5846e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4053e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 877us/step - loss: 3.6641e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 833us/step - loss: 4.7257e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5830e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2690e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0021e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3341e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7557e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.4837e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4452e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4146e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2415e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9641e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6439e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3890e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3378e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6090e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7837e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.2025e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1129e-05\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0574e-05\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.3552e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5824e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9894e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8887e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.4961e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2863e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.3792e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.6999e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 937us/step - loss: 2.7556e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4922e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.9266e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.1145e-05\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2891e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8674e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8817e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1666e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5075e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4279e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2118e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 8.3639e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6697e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7722e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3461e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6513e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3850e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4624e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8252e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.3464e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0214e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6291e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3313e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5966e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.1865e-05\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9540e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1962e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9804e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3792e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6761e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2148e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3789e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5708e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3738e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7575e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2860e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2278e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4053e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0724e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2742e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8535e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.0326e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5168e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7160e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3444e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7491e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3214e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1909e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7800e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7053e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4458e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.2814e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.1044e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.4681e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5660e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4849e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8662e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6918e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0353e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7070e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0224e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6689e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1903e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0465e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8995e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0595e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2898e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8851e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6777e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8105e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7070e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6823e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7598e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3905e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5763e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3495e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0502e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2947e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.7941e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.1653e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.4173e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.3363e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1767e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7830e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7359e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7583e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5200e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4058e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7976e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3301e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3492e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0833e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8224e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4413e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0448e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0439e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.5557e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.0452e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1335e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4912e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7553e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0324e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2574e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.8939e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6325e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1055e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.6875e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.6556e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3757e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6166e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7487e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6737e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2487e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 960us/step - loss: 3.9621e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 1000us/step - loss: 3.0241e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 937us/step - loss: 2.3344e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1115e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2430e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8657e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.0890e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5683e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.7133e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4423e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2083e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.7697e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0880e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.8675e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.9722e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4842e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3957e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2579e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3922e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 968us/step - loss: 4.6490e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2744e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7438e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9028e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9573e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5662e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6354e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9107e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4594e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.5230e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7155e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5478e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0059e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0666e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7768e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1159e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4142e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6242e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1624e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8917e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1508e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9576e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8520e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.0059e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.5037e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.2041e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5870e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.2449e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1406e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.3102e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1492e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2062e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.8559e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8348e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4824e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2070e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.3217e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.9699e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.3081e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7282e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.7748e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5152e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.4797e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.6663e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6376e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2696e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0806e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3239e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.1603e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.6119e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.6025e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0524e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4885e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.5546e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2136e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7712e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7295e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1922e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2127e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6924e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0442e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.9879e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.1554e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8281e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2813e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4003e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7588e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5711e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0426e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5537e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.0011e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5731e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.7578e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.6323e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0713e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8525e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.2335e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1858e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2774e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 983us/step - loss: 2.5542e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 964us/step - loss: 2.1200e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.9540e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.1246e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9583e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.9603e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1172e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 9.0271e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3239e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7582e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2514e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4817e-06\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1894e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2127e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3963e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9830e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1407e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 999us/step - loss: 6.9840e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0095e-05\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.1067e-05\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.3486e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.2479e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1843e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4280e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9127e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9284e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2099e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1740e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.6470e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0230e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 879us/step - loss: 6.3156e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 767us/step - loss: 6.3706e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 846us/step - loss: 6.2595e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 875us/step - loss: 6.0064e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 919us/step - loss: 5.2476e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.3093e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5770e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 967us/step - loss: 3.1750e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2764e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9058e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4138e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 953us/step - loss: 7.0957e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.3196e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8499e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.3958e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.5686e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.7687e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2007e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1606e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.3156e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.9878e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9532e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4429e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1295e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.1270e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.7708e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.7635e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.9274e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8671e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4475e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5045e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.5476e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.8540e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.9713e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.5621e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.2169e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.5222e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4084e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3585e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7068e-06\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.5666e-06\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7684e-06\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.5750e-06\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.2314e-06\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2666e-06\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.0657e-06\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.8458e-06\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.5131e-06\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.6371e-06\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.9216e-06\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7965e-06\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.0595e-06\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.5941e-06\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0958e-06\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.8378e-06\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4327e-06\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.8066e-06\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6573e-06\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.6650e-06\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1797e-06\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.3932e-06\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 8.4604e-06\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 919us/step - loss: 6.2602e-06\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.8686e-06\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.4216e-06\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 1.8550e-06\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.9682e-06\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.0687e-06\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0336e-06\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.5736e-06\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.6787e-06\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4924e-06\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3729e-06\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2043e-06\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.2188e-06\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4290e-06\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2195e-06\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1290e-06\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.2539e-06\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8973e-06\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 9.3109e-06\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.0213e-05\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8985e-06\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6985e-06\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.0588e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 4.1615e-06\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0931e-06\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.3135e-06\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.0060e-06\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.9724e-06\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.1925e-06\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5230e-06\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2260e-06\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.0891e-06\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.2731e-06\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6750e-06\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.6314e-06\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.8666e-06\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.4945e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.4800e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.9456e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1455e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.1586e-06\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.2339e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.8980e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 1.7285e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.1931e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.1062e-06\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 7.8447e-06\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 8.8567e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.6546e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 6.3062e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.4856e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 994us/step - loss: 3.5252e-06\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.3558e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 956us/step - loss: 4.3993e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 5.4761e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.8434e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.6234e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 990us/step - loss: 3.5856e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 977us/step - loss: 2.7161e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.6976e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.5736e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2291e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.8742e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 7.4450e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 4.7004e-06\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 3.3422e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 2.4158e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1271e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.1262e-06\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5239e-06\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 3.4559e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.0516e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 6.2234e-06\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 5.4208e-06\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 3.7407e-06\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.5304e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 2.0501e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luUDzVtmoX59",
        "outputId": "0894612f-9a29-4346-fd2d-48ce5c6068fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i, result in enumerate(results):\n",
        "    print(f'Week {40+i+1}: {result}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Week 41: {'mse': 0.0, 'rmse': 118.46, 'mape': 6.43}\n",
            "Week 42: {'mse': 0.0, 'rmse': 120.55, 'mape': 6.43}\n",
            "Week 43: {'mse': 0.0, 'rmse': 118.51, 'mape': 6.43}\n",
            "Week 44: {'mse': 0.0, 'rmse': 120.7, 'mape': 6.44}\n",
            "Week 45: {'mse': 0.0, 'rmse': 118.61, 'mape': 6.43}\n",
            "Week 46: {'mse': 0.0, 'rmse': 117.97, 'mape': 6.46}\n",
            "Week 47: {'mse': 0.0, 'rmse': 120.0, 'mape': 6.43}\n",
            "Week 48: {'mse': 0.0, 'rmse': 119.04, 'mape': 6.41}\n",
            "Week 49: {'mse': 0.0, 'rmse': 117.84, 'mape': 6.46}\n",
            "Week 50: {'mse': 0.0, 'rmse': 118.27, 'mape': 6.44}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOO4BnGMeuw5",
        "outputId": "b0024281-edff-43d9-c338-6b9ac96acaa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M1.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1230.0262,  956.0259, 1119.1423, 1244.4839, 1317.0518, 1246.7852,\n",
              "       1185.5779], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NudaagwghAkN"
      },
      "source": [
        "old_data = model_data[0*7:7*48 + 7]\n",
        "new_data = model_data[0*7:7*49 + 7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIMgbH54hJaU"
      },
      "source": [
        "M2 = Model(data=old_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHgw6Y6ChKuG",
        "outputId": "e9f93ac1-1cc7-4866-c3c9-65c961593dec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M2.build()\n",
        "M2.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe52d938ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7G-3V6EhL_a",
        "outputId": "81d7f748-e01e-424d-c548-02ce4d966d94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M2.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1416.2346, 1100.9097, 1291.6093, 1437.0364, 1517.7031, 1435.0581,\n",
              "       1364.0872], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGqXUHNVhNsi"
      },
      "source": [
        "M3 = Model(data=new_data,\n",
        "          variable='close',\n",
        "          predicted_period_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2j2HKrVhPA-",
        "outputId": "2fe1839e-192c-4877-c662-b81b8f97fb09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.build()\n",
        "M3.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe54478a3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHAHUZBKhQh5",
        "outputId": "9fbc3600-01f2-40df-e1c1-b96b5f940e92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.predict(denormalized=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1419.1893, 1095.9204, 1288.2698, 1438.6698, 1517.9158, 1438.534 ,\n",
              "       1362.2972], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVDAwuW2hSW-",
        "outputId": "51bf5003-e3c6-4376-a8c9-4cf0da1ce9c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "M3.evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mape': 6.41, 'mse': 0.0, 'rmse': 137.21}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7Dcq0jshUGR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}